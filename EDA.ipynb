{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "#test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26799, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check what targets we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['add_to_playlist', 'search_screening_event', 'book_restaurant',\n",
       "       'rate_book', 'get_weather', 'play_music', 'search_creative_work',\n",
       "       'no_intent'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_intent                 12645\n",
       "get_weather                2041\n",
       "play_music                 2034\n",
       "book_restaurant            2029\n",
       "search_screening_event     2018\n",
       "search_creative_work       2014\n",
       "rate_book                  2009\n",
       "add_to_playlist            2009\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quer ir para um lugar apropriado para nos pegarmos?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[26774].Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Request    272\n",
       "Label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at unique words (lower case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = CountVectorizer().fit(train['Request'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '003½',\n",
       " '006',\n",
       " '007',\n",
       " '00h',\n",
       " '00s',\n",
       " '01',\n",
       " '02',\n",
       " '03',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '07',\n",
       " '08',\n",
       " '09',\n",
       " '0h',\n",
       " '0h00',\n",
       " '0i',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '101',\n",
       " '103rd',\n",
       " '105th',\n",
       " '1098',\n",
       " '10h',\n",
       " '10h31',\n",
       " '10th',\n",
       " '11',\n",
       " '116th',\n",
       " '117',\n",
       " '119',\n",
       " '11h',\n",
       " '12',\n",
       " '120',\n",
       " '125',\n",
       " '129',\n",
       " '12h',\n",
       " '12h00',\n",
       " '12º',\n",
       " '13',\n",
       " '131',\n",
       " '135th',\n",
       " '138th',\n",
       " '13h',\n",
       " '14',\n",
       " '141',\n",
       " '144',\n",
       " '145',\n",
       " '14h',\n",
       " '15',\n",
       " '1500',\n",
       " '1525',\n",
       " '157',\n",
       " '16',\n",
       " '163',\n",
       " '1634',\n",
       " '165',\n",
       " '16h',\n",
       " '17',\n",
       " '170',\n",
       " '1715',\n",
       " '1737',\n",
       " '175',\n",
       " '18',\n",
       " '180',\n",
       " '1814',\n",
       " '183',\n",
       " '1844',\n",
       " '19',\n",
       " '190',\n",
       " '1900',\n",
       " '1933',\n",
       " '1938',\n",
       " '1942',\n",
       " '1945',\n",
       " '1950',\n",
       " '1951',\n",
       " '1952',\n",
       " '1953',\n",
       " '1954',\n",
       " '1955',\n",
       " '1956',\n",
       " '1957',\n",
       " '1958',\n",
       " '1959',\n",
       " '1960',\n",
       " '1961',\n",
       " '1962',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '19h',\n",
       " '19º',\n",
       " '1o',\n",
       " '1x1',\n",
       " '1ª',\n",
       " '1º',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '201',\n",
       " '2010',\n",
       " '2010s',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '2020',\n",
       " '2021',\n",
       " '2022',\n",
       " '2023',\n",
       " '2024',\n",
       " '2025',\n",
       " '2026',\n",
       " '2027',\n",
       " '2028',\n",
       " '2029',\n",
       " '2030',\n",
       " '2031',\n",
       " '2032',\n",
       " '2033',\n",
       " '2034',\n",
       " '2035',\n",
       " '2036',\n",
       " '2037',\n",
       " '2038',\n",
       " '2039',\n",
       " '2040',\n",
       " '207th',\n",
       " '20h',\n",
       " '20h44',\n",
       " '20th',\n",
       " '20º',\n",
       " '20ºc',\n",
       " '21',\n",
       " '2112',\n",
       " '212',\n",
       " '2120',\n",
       " '213',\n",
       " '2150',\n",
       " '21h',\n",
       " '21st',\n",
       " '22',\n",
       " '22h',\n",
       " '23',\n",
       " '24',\n",
       " '240v',\n",
       " '241',\n",
       " '25',\n",
       " '250',\n",
       " '257',\n",
       " '25th',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '2a',\n",
       " '2cm',\n",
       " '2gether',\n",
       " '2h',\n",
       " '2min',\n",
       " '2shh',\n",
       " '2ª',\n",
       " '2º',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30º',\n",
       " '30ºc',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '345',\n",
       " '35',\n",
       " '350',\n",
       " '36',\n",
       " '365',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '3d',\n",
       " '3h',\n",
       " '3min',\n",
       " '3rd',\n",
       " '3x4',\n",
       " '3º',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '41',\n",
       " '416',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '4400',\n",
       " '45',\n",
       " '450',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '4813',\n",
       " '49',\n",
       " '4h00',\n",
       " '4th',\n",
       " '4º',\n",
       " '50',\n",
       " '500',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '53rd',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '58',\n",
       " '59',\n",
       " '59º',\n",
       " '5h',\n",
       " '5o',\n",
       " '5º',\n",
       " '60',\n",
       " '600',\n",
       " '60s',\n",
       " '61',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '68m',\n",
       " '69th',\n",
       " '6h',\n",
       " '70',\n",
       " '70s',\n",
       " '72',\n",
       " '72nd',\n",
       " '74',\n",
       " '75cm2',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '7even',\n",
       " '7h',\n",
       " '80',\n",
       " '800',\n",
       " '807',\n",
       " '80s',\n",
       " '81',\n",
       " '847',\n",
       " '86',\n",
       " '88',\n",
       " '8h30',\n",
       " '8th',\n",
       " '8º',\n",
       " '90',\n",
       " '90s',\n",
       " '911',\n",
       " '94',\n",
       " '96',\n",
       " '97',\n",
       " '99',\n",
       " '9am',\n",
       " '9h',\n",
       " '9th',\n",
       " '9º',\n",
       " 'a11',\n",
       " 'aagathadi',\n",
       " 'aaliyah',\n",
       " 'aance',\n",
       " 'aap',\n",
       " 'aaron',\n",
       " 'abacaxi',\n",
       " 'abacus',\n",
       " 'abafado',\n",
       " 'abafador',\n",
       " 'abaixo',\n",
       " 'abandonado',\n",
       " 'abandonar',\n",
       " 'abandonos',\n",
       " 'abano',\n",
       " 'abasi',\n",
       " 'abastados',\n",
       " 'abastecer',\n",
       " 'abate',\n",
       " 'abater',\n",
       " 'abatida',\n",
       " 'abatido',\n",
       " 'abatte',\n",
       " 'abbath',\n",
       " 'abbott',\n",
       " 'abbruzzese',\n",
       " 'abby',\n",
       " 'abdel',\n",
       " 'abdication',\n",
       " 'abdollahzadeh',\n",
       " 'abdominais',\n",
       " 'abdu',\n",
       " 'abdul',\n",
       " 'abe',\n",
       " 'abel',\n",
       " 'abelha',\n",
       " 'abelhas',\n",
       " 'abençoado',\n",
       " 'abençoados',\n",
       " 'abercrombie',\n",
       " 'aberração',\n",
       " 'aberta',\n",
       " 'abertas',\n",
       " 'aberto',\n",
       " 'abertura',\n",
       " 'abhyankar',\n",
       " 'abigail',\n",
       " 'abington',\n",
       " 'abismo',\n",
       " 'abolido',\n",
       " 'abolição',\n",
       " 'abominations',\n",
       " 'abominável',\n",
       " 'abonem',\n",
       " 'abordagem',\n",
       " 'aboriginal',\n",
       " 'aborrecido',\n",
       " 'aborreça',\n",
       " 'about',\n",
       " 'abra',\n",
       " 'abrange',\n",
       " 'abrar',\n",
       " 'abrasiva',\n",
       " 'abraçar',\n",
       " 'abraço',\n",
       " 'abraçá',\n",
       " 'abre',\n",
       " 'abrem',\n",
       " 'abreviar',\n",
       " 'abri',\n",
       " 'abrigo',\n",
       " 'abrigos',\n",
       " 'abril',\n",
       " 'abrimos',\n",
       " 'abrir',\n",
       " 'abriram',\n",
       " 'abriu',\n",
       " 'abrí',\n",
       " 'absoluta',\n",
       " 'absolutamente',\n",
       " 'absoluto',\n",
       " 'absolver',\n",
       " 'absorva',\n",
       " 'absorver',\n",
       " 'abstinence',\n",
       " 'absurda',\n",
       " 'abuja',\n",
       " 'abundância',\n",
       " 'abutres',\n",
       " 'abóbora',\n",
       " 'ac',\n",
       " 'acaba',\n",
       " 'acabado',\n",
       " 'acabam',\n",
       " 'acabamos',\n",
       " 'acabando',\n",
       " 'acabar',\n",
       " 'acabaram',\n",
       " 'acabarei',\n",
       " 'acabarem',\n",
       " 'acabaremos',\n",
       " 'acabarfazendo',\n",
       " 'acabarão',\n",
       " 'acabe',\n",
       " 'acabei',\n",
       " 'acabemos',\n",
       " 'acabo',\n",
       " 'acabou',\n",
       " 'academe',\n",
       " 'academia',\n",
       " 'academy',\n",
       " 'acalma',\n",
       " 'acalmar',\n",
       " 'acalmarem',\n",
       " 'acalme',\n",
       " 'acampamento',\n",
       " 'acampar',\n",
       " 'acapella',\n",
       " 'acaso',\n",
       " 'access',\n",
       " 'acchiappafantasmi',\n",
       " 'accion',\n",
       " 'accused',\n",
       " 'ace',\n",
       " 'aceita',\n",
       " 'aceitamos',\n",
       " 'aceitar',\n",
       " 'aceitarem',\n",
       " 'aceitação',\n",
       " 'aceite',\n",
       " 'aceito',\n",
       " 'aceitou',\n",
       " 'aceitável',\n",
       " 'acelebrado',\n",
       " 'acelerar',\n",
       " 'acenda',\n",
       " 'acende',\n",
       " 'acendendo',\n",
       " 'acender',\n",
       " 'aceno',\n",
       " 'acerca',\n",
       " 'acerta',\n",
       " 'acertado',\n",
       " 'acertamos',\n",
       " 'acertar',\n",
       " 'acerto',\n",
       " 'acertou',\n",
       " 'acessando',\n",
       " 'acessar',\n",
       " 'acessarmos',\n",
       " 'acesse',\n",
       " 'acesso',\n",
       " 'acessos',\n",
       " 'acessível',\n",
       " 'acessórios',\n",
       " 'acha',\n",
       " 'achados',\n",
       " 'acham',\n",
       " 'achamos',\n",
       " 'achar',\n",
       " 'acharia',\n",
       " 'acharmos',\n",
       " 'acharão',\n",
       " 'achas',\n",
       " 'ache',\n",
       " 'achei',\n",
       " 'achemos',\n",
       " 'acho',\n",
       " 'achou',\n",
       " 'achá',\n",
       " 'acid',\n",
       " 'acidentalmente',\n",
       " 'acidente',\n",
       " 'acidentes',\n",
       " 'acima',\n",
       " 'acionando',\n",
       " 'acionar',\n",
       " 'acionista',\n",
       " 'acionou',\n",
       " 'acolhe',\n",
       " 'acoliþii',\n",
       " 'acomodar',\n",
       " 'acomodação',\n",
       " 'acomodações',\n",
       " 'acompanha',\n",
       " 'acompanhado',\n",
       " 'acompanhamento',\n",
       " 'acompanhante',\n",
       " 'acompanhar',\n",
       " 'acompanhe',\n",
       " 'acompañado',\n",
       " 'aconselhamento',\n",
       " 'aconselhe',\n",
       " 'aconselho',\n",
       " 'aconselhou',\n",
       " 'aconselhássemos',\n",
       " 'aconselhável',\n",
       " 'acontece',\n",
       " 'acontecem',\n",
       " 'acontecendo',\n",
       " 'acontecer',\n",
       " 'aconteceram',\n",
       " 'acontecerem',\n",
       " 'aconteceriam',\n",
       " 'acontecerá',\n",
       " 'aconteceu',\n",
       " 'acontecido',\n",
       " 'acontecimentos',\n",
       " 'aconteça',\n",
       " 'acopla',\n",
       " 'acorda',\n",
       " 'acordada',\n",
       " 'acordadas',\n",
       " 'acordado',\n",
       " 'acordar',\n",
       " 'acordares',\n",
       " 'acordarmos',\n",
       " 'acordasse',\n",
       " 'acordei',\n",
       " 'acordeom',\n",
       " 'acordo',\n",
       " 'acorrentado',\n",
       " 'acostumado',\n",
       " 'acostumar',\n",
       " 'acostume',\n",
       " 'acoustic',\n",
       " 'acoustics',\n",
       " 'acredita',\n",
       " 'acreditam',\n",
       " 'acreditando',\n",
       " 'acreditar',\n",
       " 'acreditarem',\n",
       " 'acreditava',\n",
       " 'acredite',\n",
       " 'acreditem',\n",
       " 'acredito',\n",
       " 'acreditávamos',\n",
       " 'acres',\n",
       " 'acrescentar',\n",
       " 'acrescente',\n",
       " 'acrescento',\n",
       " 'across',\n",
       " 'acréscimo',\n",
       " 'act',\n",
       " 'acta',\n",
       " 'active',\n",
       " 'activeperl',\n",
       " 'actividade',\n",
       " 'activity',\n",
       " 'actores',\n",
       " 'actos',\n",
       " 'actualização',\n",
       " 'acumula',\n",
       " 'acumularão',\n",
       " 'acupuntura',\n",
       " 'acusada',\n",
       " 'acusado',\n",
       " 'acusando',\n",
       " 'acusação',\n",
       " 'acusações',\n",
       " 'acworth',\n",
       " 'acção',\n",
       " 'acúmulo',\n",
       " 'acústica',\n",
       " 'acústicas',\n",
       " 'acústico',\n",
       " 'acústicos',\n",
       " 'ad',\n",
       " 'adaga',\n",
       " 'adam',\n",
       " 'adama',\n",
       " 'adams',\n",
       " 'adapta',\n",
       " 'adaptar',\n",
       " 'adaptativa',\n",
       " 'adapte',\n",
       " 'adassa',\n",
       " 'add',\n",
       " 'addicted',\n",
       " 'addo',\n",
       " 'address',\n",
       " 'adega',\n",
       " 'adelaide',\n",
       " 'adele',\n",
       " 'adeline',\n",
       " 'adentrarmos',\n",
       " 'adeptos',\n",
       " 'adequado',\n",
       " 'aderir',\n",
       " 'aderência',\n",
       " 'adeus',\n",
       " 'adeyto',\n",
       " 'adiando',\n",
       " 'adiantado',\n",
       " 'adiantando',\n",
       " 'adiante',\n",
       " 'adiar',\n",
       " 'adic',\n",
       " 'adici',\n",
       " 'adicio',\n",
       " 'adicion',\n",
       " 'adiciona',\n",
       " 'adicionada',\n",
       " 'adicionadas',\n",
       " 'adicionado',\n",
       " 'adicionados',\n",
       " 'adicionando',\n",
       " 'adicionar',\n",
       " 'adicionará',\n",
       " 'adicionasse',\n",
       " 'adicionassem',\n",
       " 'adicione',\n",
       " 'adicioná',\n",
       " 'adiesel',\n",
       " 'adieu',\n",
       " 'aditivo',\n",
       " 'adivinhar',\n",
       " 'adivinharem',\n",
       " 'adivinhou',\n",
       " 'adição',\n",
       " 'adjetivo',\n",
       " 'adkins',\n",
       " 'adler',\n",
       " 'administram',\n",
       " 'administrando',\n",
       " 'administration',\n",
       " 'administrativo',\n",
       " 'administrativos',\n",
       " 'administração',\n",
       " 'administrá',\n",
       " 'admira',\n",
       " 'admirar',\n",
       " 'admirarem',\n",
       " 'admiro',\n",
       " 'admirável',\n",
       " 'admiti',\n",
       " 'admitir',\n",
       " 'adn',\n",
       " 'adobe',\n",
       " 'adolescente',\n",
       " 'adolescentes',\n",
       " 'adolescência',\n",
       " 'adolf',\n",
       " 'adora',\n",
       " 'adorado',\n",
       " 'adoram',\n",
       " 'adorar',\n",
       " 'adoraria',\n",
       " 'adoraríamos',\n",
       " 'adorava',\n",
       " 'adoração',\n",
       " 'adormecer',\n",
       " 'adormecida',\n",
       " 'adorno',\n",
       " 'adoro',\n",
       " 'adoráveis',\n",
       " 'adorável',\n",
       " 'adotar',\n",
       " 'adotiva',\n",
       " 'adotivo',\n",
       " 'adquirem',\n",
       " 'adrenalina',\n",
       " 'adrenaline',\n",
       " 'adrian',\n",
       " 'adriana',\n",
       " 'adrianna',\n",
       " 'adriças',\n",
       " 'adulta',\n",
       " 'adulto',\n",
       " 'adultos',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adversário',\n",
       " 'advertindo',\n",
       " 'advogada',\n",
       " 'advogado',\n",
       " 'advogados',\n",
       " 'advogar',\n",
       " 'adyathe',\n",
       " 'aerodinâmica',\n",
       " 'aeronave',\n",
       " 'aeroporto',\n",
       " 'aeroportos',\n",
       " 'aeródromo',\n",
       " 'afasta',\n",
       " 'afastado',\n",
       " 'afastam',\n",
       " 'afastar',\n",
       " 'afaste',\n",
       " 'afdlin',\n",
       " 'afectar',\n",
       " 'afeganistão',\n",
       " 'afegão',\n",
       " 'afetar',\n",
       " 'afetou',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'afflek',\n",
       " 'afi',\n",
       " 'afiado',\n",
       " 'afim',\n",
       " 'afinal',\n",
       " 'afinar',\n",
       " 'afinidade',\n",
       " 'afirmar',\n",
       " 'afirmação',\n",
       " 'afirmo',\n",
       " 'aflame',\n",
       " 'aflige',\n",
       " 'afogamento',\n",
       " 'afogar',\n",
       " 'afortunada',\n",
       " 'afortunados',\n",
       " 'afresco',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africana',\n",
       " 'africanizadas',\n",
       " 'africano',\n",
       " 'africanos',\n",
       " 'afro',\n",
       " 'afrodite',\n",
       " 'afronta',\n",
       " 'after',\n",
       " 'aftercluv',\n",
       " 'afterlife',\n",
       " 'afternoon',\n",
       " 'afterwork',\n",
       " 'afundada',\n",
       " 'afundado',\n",
       " 'afundar',\n",
       " 'ag',\n",
       " 'agachada',\n",
       " 'agachamento',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agate',\n",
       " 'agatsuma',\n",
       " 'age',\n",
       " 'agenda',\n",
       " 'agendada',\n",
       " 'agendado',\n",
       " 'agendados',\n",
       " 'agendamento',\n",
       " 'agende',\n",
       " 'agente',\n",
       " 'agentes',\n",
       " 'ages',\n",
       " 'aggregor',\n",
       " 'agincourt',\n",
       " 'agindo',\n",
       " 'agir',\n",
       " 'agirmos',\n",
       " 'agitado',\n",
       " 'agitar',\n",
       " 'agitação',\n",
       " 'agite',\n",
       " 'agiu',\n",
       " 'agnew',\n",
       " 'agnolotti',\n",
       " 'ago',\n",
       " 'agonia',\n",
       " 'agor',\n",
       " 'agora',\n",
       " 'agostinho',\n",
       " 'agosto',\n",
       " 'agraciou',\n",
       " 'agrada',\n",
       " 'agradar',\n",
       " 'agradecendo',\n",
       " 'agradecer',\n",
       " 'agradecido',\n",
       " 'agradecê',\n",
       " 'agradeço',\n",
       " 'agradou',\n",
       " 'agradáveis',\n",
       " 'agradável',\n",
       " 'agreable',\n",
       " 'agressiva',\n",
       " 'agressivo',\n",
       " 'agressão',\n",
       " 'agressões',\n",
       " 'agricultor',\n",
       " 'agua',\n",
       " 'aguada',\n",
       " 'aguardando',\n",
       " 'aguardar',\n",
       " 'aguardará',\n",
       " 'aguarela',\n",
       " 'aguarrás',\n",
       " 'aguenta',\n",
       " 'aguentando',\n",
       " 'aguentar',\n",
       " 'aguila',\n",
       " 'aguilar',\n",
       " 'agulha',\n",
       " 'agulhas',\n",
       " 'agência',\n",
       " 'agências',\n",
       " 'agüenta',\n",
       " 'agüentar',\n",
       " 'ah',\n",
       " 'ahbez',\n",
       " 'ahmad',\n",
       " 'ahmed',\n",
       " 'ai',\n",
       " 'aiba',\n",
       " 'aidna',\n",
       " 'aids',\n",
       " 'aiken',\n",
       " 'ainda',\n",
       " 'aioli',\n",
       " 'aion',\n",
       " 'air',\n",
       " 'aira',\n",
       " 'airbnb',\n",
       " 'aire',\n",
       " 'airey',\n",
       " 'airi',\n",
       " 'airto',\n",
       " 'aise',\n",
       " 'aisha',\n",
       " 'aitken',\n",
       " 'aj',\n",
       " 'ajar',\n",
       " 'ajeitar',\n",
       " 'ajinoam',\n",
       " 'ajoelhe',\n",
       " 'ajoy',\n",
       " 'ajuda',\n",
       " 'ajudam',\n",
       " 'ajudando',\n",
       " 'ajudante',\n",
       " 'ajudar',\n",
       " 'ajudaram',\n",
       " 'ajudarei',\n",
       " 'ajudarem',\n",
       " 'ajudares',\n",
       " 'ajudaria',\n",
       " 'ajudaríamos',\n",
       " 'ajude',\n",
       " 'ajudinha',\n",
       " 'ajudou',\n",
       " 'ajudá',\n",
       " 'ajustando',\n",
       " 'ajustar',\n",
       " 'ajustes',\n",
       " 'ajusto',\n",
       " 'ajustá',\n",
       " 'ak',\n",
       " 'akb48',\n",
       " 'akbar',\n",
       " 'akers',\n",
       " 'akhtar',\n",
       " 'aki',\n",
       " 'akinyele',\n",
       " 'akira',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alabasta',\n",
       " 'alada',\n",
       " 'alain',\n",
       " 'alam',\n",
       " 'alamo',\n",
       " 'alamosa',\n",
       " 'alan',\n",
       " 'alarme',\n",
       " 'alas',\n",
       " 'alasca',\n",
       " 'alasdair',\n",
       " 'alaska',\n",
       " 'alba',\n",
       " 'albano',\n",
       " 'albarn',\n",
       " 'albergue',\n",
       " 'albert',\n",
       " 'alberton',\n",
       " 'albertson',\n",
       " 'albini',\n",
       " 'albino',\n",
       " 'album',\n",
       " 'albânia',\n",
       " 'alcance',\n",
       " 'alcançado',\n",
       " 'alcançando',\n",
       " 'alcançar',\n",
       " 'alcançariam',\n",
       " 'alcateia',\n",
       " 'alcatra',\n",
       " 'alcatrão',\n",
       " 'alcaçuz',\n",
       " 'alce',\n",
       " 'alcoólatra',\n",
       " 'aldeia',\n",
       " 'alden',\n",
       " 'alderwood',\n",
       " 'aldo',\n",
       " 'aldrich',\n",
       " 'aleatórias',\n",
       " 'aleatório',\n",
       " 'aleatórios',\n",
       " 'alec',\n",
       " 'alecrim',\n",
       " 'alegado',\n",
       " 'alegando',\n",
       " 'alegre',\n",
       " 'alegres',\n",
       " 'alegria',\n",
       " 'alejandro',\n",
       " 'alemanha',\n",
       " 'alemã',\n",
       " 'alemães',\n",
       " 'alemão',\n",
       " 'alerce',\n",
       " 'alergias',\n",
       " 'alerta',\n",
       " 'alertá',\n",
       " 'aletria',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandra',\n",
       " 'alexandria',\n",
       " 'alexandrovich',\n",
       " 'alexia',\n",
       " 'alexis',\n",
       " 'alfa',\n",
       " 'alfabeto',\n",
       " 'alface',\n",
       " 'alfaiate',\n",
       " 'alfalfa',\n",
       " 'alfie',\n",
       " 'alfinete',\n",
       " 'alfonso',\n",
       " 'alfonzo',\n",
       " 'alfred',\n",
       " 'alfreda',\n",
       " 'alfredo',\n",
       " 'alg',\n",
       " 'algas',\n",
       " 'algers',\n",
       " 'algo',\n",
       " 'algodão',\n",
       " 'algu',\n",
       " 'alguem',\n",
       " 'algum',\n",
       " 'alguma',\n",
       " 'algumas',\n",
       " 'alguns',\n",
       " 'algures',\n",
       " 'alguém',\n",
       " 'alguêm',\n",
       " 'alheia',\n",
       " 'alho',\n",
       " 'ali',\n",
       " 'aliados',\n",
       " 'aliança',\n",
       " 'alianças',\n",
       " 'alicates',\n",
       " 'alice',\n",
       " 'alices',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'aliens',\n",
       " 'alienígena',\n",
       " 'alienígenas',\n",
       " 'alimentado',\n",
       " 'alimentamos',\n",
       " 'alimentando',\n",
       " 'alimentar',\n",
       " 'alimentares',\n",
       " 'alimentação',\n",
       " 'alimento',\n",
       " 'alimentos',\n",
       " 'alinhamento',\n",
       " 'alisar',\n",
       " 'alisha',\n",
       " 'alison',\n",
       " 'alisou',\n",
       " 'alissa',\n",
       " 'aliste',\n",
       " 'alive',\n",
       " 'aliviado',\n",
       " 'aliviar',\n",
       " 'alizadeh',\n",
       " 'aliás',\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn everythin into lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.Request = train.Request.str.lower()\n",
    "test.Request = test.Request.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_idx = (train.Label == 'play_music') | (train.Label == 'add_to_playlist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_to_playlist         466\n",
       "no_intent                23\n",
       "rate_book                 3\n",
       "play_music                1\n",
       "search_creative_work      1\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.Request.str.contains('Adicionar')].Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Request</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adicionar música tomohisa yamashita à minha li...</td>\n",
       "      <td>add_to_playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eu quero adicionando Aprite le finestre à minh...</td>\n",
       "      <td>add_to_playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Eu quero adicionar uma música de wc clark para...</td>\n",
       "      <td>add_to_playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adicione a música à de reprodução do Metal.</td>\n",
       "      <td>add_to_playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>colocou o artista Emre Aydin na playlist Happy...</td>\n",
       "      <td>add_to_playlist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Request            Label\n",
       "0   Adicionar música tomohisa yamashita à minha li...  add_to_playlist\n",
       "1   Eu quero adicionando Aprite le finestre à minh...  add_to_playlist\n",
       "7   Eu quero adicionar uma música de wc clark para...  add_to_playlist\n",
       "11        Adicione a música à de reprodução do Metal.  add_to_playlist\n",
       "31  colocou o artista Emre Aydin na playlist Happy...  add_to_playlist"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.Label == 'add_to_playlist')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things with 'música' that aren't related to 'play_music' or 'add_to_playlist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_music_idx = ~((train.Label == 'play_music') | (train.Label == 'add_to_playlist'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_related_to_music = train[not_music_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_related_to_music.Request.str.contains('música').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_related_to_music.Request.str.contains('musica').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_book_restaurant = (train.Label == 'book_restaurant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.fit(train[is_book_restaurant].Request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_with_meta_features(df, text_col, stopwords):\n",
    "    df = df.copy()\n",
    "    stop_words = set(stopwords)\n",
    "    \n",
    "    df['words'] = df[text_col].str.split(' ').map(len)\n",
    "    df['words_not_stopword'] = df[text_col].apply(\n",
    "        lambda x: len([t for t in x.split(' ') if t not in stop_words]))\n",
    "    df['commas'] = df[text_col].str.count(',')\n",
    "    df['upper'] = df[text_col].map(lambda x: map(str.isupper, x)).map(sum)\n",
    "    df['capitalized'] = df[text_col].map(lambda x: map(str.istitle, x)).map(sum)\n",
    "    df['avg_word_length'] = df[text_col].apply(\n",
    "        lambda x: np.mean([len(t) for t in x.split(' ') \n",
    "                           if t not in stop_words]) \n",
    "        if len([len(t) for t in x.split(' ') \n",
    "                if t not in stop_words]) > 0 else 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_list = [\n",
    "    ('umidade', 'humidade'), \n",
    "    (r'\\búltim\\b', 'último')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(train.Request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(cv.vocabulary_.items(), key=lambda e: -e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.Request.str.contains(r'\\búltim\\b')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load('pt_core_news_sm')\n",
    "nlp = spacy.load('xx_ent_wiki_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(nlp.pipe(train.Request, n_threads=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_entities = []\n",
    "rows_without_entities = []\n",
    "all_entities = []\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    entities = doc.ents\n",
    "    if len(entities) == 0:\n",
    "        rows_without_entities.append(i)\n",
    "    else: \n",
    "        rows_with_entities.append(i)\n",
    "        \n",
    "for i in rows_with_entities:\n",
    "    all_entities += list(docs[i].ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_entities = list(\n",
    "    set(\n",
    "        list(\n",
    "            sorted(\n",
    "                map(lambda e: (str(e.as_doc()), e.label_), all_entities), \n",
    "                key=lambda e: e[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(all_unique_entities, key=lambda e: e[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = Counter(map(lambda e: (str(e.as_doc()), e.label_), all_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entidades_sem_sentido = [\n",
    "    ('Adicionar', ''), \n",
    "    ('Vamos', ''), \n",
    "    ('Preciso', ''), \n",
    "    ('Diga', ''), \n",
    "    ('Avalie', ''), \n",
    "    ('Mostre', ''), \n",
    "    ('Reproduzir', ''), \n",
    "    ('Mostre', ''), \n",
    "    ('Precisa', ''), \n",
    "    ('Adicionar', ''), \n",
    "    ('Olhe', ''), \n",
    "    ('Quero', ''), \n",
    "    ('Encontre', ''), \n",
    "    ('Você', ''), \n",
    "    ('Vamos falar ', '')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df = pd.DataFrame(cc.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = docs[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in z:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nlp(\"eu sou o Bruno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in g:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiências com regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"esta frase tem uma pessoa chamada Bruno Dias e outra chamada Silva Dias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = r\"([A-Z][a-z]+(?=\\s[A-Z])(?:\\s[A-Z][a-z]+)+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(p, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
